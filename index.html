<!doctype html>
<html lang="en">
  <head>
    <title>DeepSpatial 2024</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="https://fonts.googleapis.com/css?family=Rubik:300,400,700|Oswald:400,700" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/jquery.fancybox.min.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
    <link rel="stylesheet" href="css/aos.css">
	<link rel="icon" href="images/DeepSpatial2020icon.png">

    <!-- MAIN CSS -->
    <link rel="stylesheet" href="css/style.css">
    <style type="text/css">
	.myimg{
	  width:200px;
	  height:200px;
	  object-fit:cover;
	  border-radius:50%;
	}</style>
  </head>
  <body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">
  <!--<img src="images/scr_deepspatial2020.png" style="display:none" >-->
  <div id="overlayer"></div>
  <div class="loader">
    <div class="spinner-border text-primary" role="status">
      <span class="sr-only">Loading...</span>
    </div>
  </div>

  <div class="site-wrap"  id="home-section">
	  <div class="site-mobile-menu site-navbar-target">
		  <div class="site-mobile-menu-header">
			  <div class="site-mobile-menu-close mt-3">
				  <span class="icon-close2 js-menu-toggle"></span>
			  </div>
		  </div>
		  <div class="site-mobile-menu-body"></div>
	  </div>
	  
	  <div class="top-bar"> </div>

    <header class="site-navbar js-sticky-header site-navbar-target" role="banner">
	    <div class="container">
		    <div class="row align-items-center position-relative">
			    <!--<div class="site-logo">
			    <a href="index.html" class="text-black"><span class="text-primary">DeepSpatial 2020</a>
		    </div>-->
		<div class="col-12">
			<nav class="site-navigation text-right ml-auto " role="navigation">
				<ul class="site-menu main-menu js-clone-nav ml-auto d-none d-lg-block">
					<li><a href="index.html#desp-section" class="nav-link">Home</a></li>

            <li><a href="index.html#program-section" class="nav-link">Program</a></li>
				<li><a href="index.html#keynotes-section" class="nav-link">Keynotes Speakers</a></li>
        <li><a href="index.html#panel-section" class="nav-link">Panel</a></li>
                <li><a href="index.html#accep-paper-section" class="nav-link">Accepted Papers</a></li>

        <li><a href="index.html#org-com-section" class="nav-link">Organization Committee</a></li>
        <li><a href="index.html#paper-sub-section" class="nav-link active">Paper Submission</a></li>
        <!--        <li><a href="#keynotes-description-section" class="nav-link">Keynotes</a></li>-->
		<!--<li><a href="#contact-info" class="nav-link">Contact Us</a></li>-->
              </ul>
              </nav>

            </div>

          <div class="toggle-button d-inline-block d-lg-none"><a href="index.html#" class="site-menu-toggle py-5 js-menu-toggle text-black"><span class="icon-menu h3"></span></a></div>

        </div>
      </div>

    </header>

	<div class="site-section-cover overlay img-bg-section" style="background-image: url('images/hero_3.jpg'); " >
		<div class="container">
			<div class="row align-items-center justify-content-center text-center">
				<div class="col-md-12 col-lg-7">
					<h1 data-aos="fade-up" data-aos-delay="">Welcome to DeepSpatial 2024</h1>
					<p class="mb-5" data-aos="fade-up" data-aos-delay="100">4th ACM SIGKDD Workshop on Deep Learning for Spatiotemporal Data, Applications, and Systems<br/>  August 26, 2024 (Tentative)<br/> Room: TBD<br/> KDD-organized Conference</p>
					<!-- <p data-aos="fade-up" data-aos-delay="200"><a href="https://whova.com/portal/webapp/kdd_202008/Agenda/1140679" class="btn btn-outline-white border-w-2 btn-md"> Zoom Link to Attend the Online Workshop in 8:00AM-12:00PM (SST), 1:00pm-4:50pm (PDT timezone) on Aug 24, 2020</a></p><div align="center"> -->
					<!--<img src="images/acmlogo.gif" align="middle" alt="">
					<img src="images/kdd_logo.png" align="middle" alt="">-->
				</div>
			</div>
		</div>
	</div>

</div>

      <br>
	  
	 <div class="site-section">
		  <div class="block__73694 mb-2" id="desp-section">
			<div class="container">
			  <div class="row d-flex no-gutters align-items-stretch">
				<div class="col-lg-12" data-aos="" data-aos-delay="">
			<p class="mb-3 text-black">Building on previous successful DeepSpatial’20, DeepSpatial’21, and DeepSpatial’22 workshops at SIGKDD, we are proposing the 4th SIGKDD Workshop on Deep Learning for Spatio-temporal Data, Applications, and Systems (DeepSpatial’24) at the 30th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining as a full-day workshop. This year’s workshop features several new items, including emerging themes related to foundation models for spatiotemporal data and their interdisciplinary scientific applications, two distinguished keynote speakers, and two discussion panels on ongoing debates in the field.</p>
				<center>
				    <p class="mb-5 text-black"><font size="12"><b>Why NOW?</b></font></p>
			      	</center>
			<p class="mb-3 text-black">Over the last decades, a rapidly growing volume of spatiotemporal data has been collected from smartphones and GPS, terrestrial, seaborne, airborne, and spaceborne sensors, as well as computational simulations. Meanwhile, advances in deep learning technologies, especially the recent breakthroughs of generative AI and foundation models such as Large Language Models (LLMs) and Large Vision Models (LVMs), have achieved tremendous success in natural language processing and computer vision applications. There are growing anticipations of the same level of accomplishment of AI on spatiotemporal data in tackling grand societal challenges, such as national water resource management, monitoring coastal hazards, energy, and food security, as well as mitigation and adaptation to climate change. When deep learning, especially emerging foundation models, intersects spatiotemporal data in scientific domains, it opens up new opportunities and challenges. The workshop aims to bring together academic researchers in both AI and scientific domains, government program managers, leaders from non-profit organizations, as well as industry executives to brainstorm and debate on the emerging opportunities and novel challenges of deep learning (foundation models) for spatiotemporal data inspired by real-world scientific applications.</p>
				<center>
				    <p class="mb-5 text-black"><font size="12"><b>Aims and Scope</b></font></p>
			      	</center>
                  <p class="mb-3 text-black">This workshop will provide a premium platform for researchers from both academia and industry to exchange ideas on emerging research themes related to deep learning for spatiotemporal data, particularly on Foundation Models (LLMs, LVMs) and their interdisciplinary scientific applications. <br/><br/><b>Topics of Interest</b>: We will welcome submissions under relevant topics including, <b>but not limited to<b>, the following four broad categories:</p>

			<p class="mb-3 text-black"><b>Emerging Foundation Models and Deep Learning for Spatiotemporal Data:</b>
			<ul>
			    <li>Technical advances in pretraining, fine-tuning, prompting, and in-context learning of LLMs as motivated by geographical and spatiotemporal problems</li>
			    <li>Applying or customizing existing foundation models to spatiotemporal data</li>
			    <li>Novel design of foundation models to address the unique characteristics of spatiotemporal data that are different from video or text</li>
			    <li>Multi-modal foundational models that integrate unstructured and structured (e.g., sequences or networks) spatiotemporal data</li>
			    <li>Grounding foundation models with physical knowledge</li>
			    <li>Ethical issues of foundation models (fairness, interpretability, transparency)</li>
			    <li>Identifying and mitigating risks and caveats for foundation models in spatiotemporal applications</li>
			</ul>
			</p>
			<p class="mb-3 text-black"><b>Spatial Representation and Networks:</b>
			<ul>
			    <li>Spatial representation learning and deep neural networks for spatio-temporal data and geometric data</li>
			    <li>Physics-guided and interpretable deep learning for spatiotemporal data</li>
			    <li>Deep generative models for spatio-temporal data</li>
			    <li>Deep reinforcement learning for spatiotemporal decision-making problems</li>
			</ul>
			</p>
			<p class="mb-3 text-black"><b>Responsible GeoAI and Applications:</b>
			<ul>
			    <li>Interdisciplinary Applications: Oceanography, natural disaster management, weather forecasting, agriculture, renewable energy, transportation and mobility applications, manufacturing and construction, biological applications (e.g., molecules, proteins, brain, etc.)</li>
			    <li>Public Safety and Health: Geosocial media and citizen science, spatial event prediction and forecasting (e.g., public safety, public health, politics)</li>
			    <li>Cyberinfrastructures: GeoAI Cyberinfrastructure for Earth Science Applications, Geoinformation System (GIS) systems using deep learning, GeoAI scientific workflow development and optimization</li>
			    <li>Sustainable Practices: Energy efficiency and carbon footprint, efficiency deployment on edge devices</li>
			</ul>
			</p>
			<p class="mb-3 text-black"><b>Benchmarking and Optimization:</b>
			<ul>
			    <li>Novel Spatial Deep Learning Cyberinfrastructures</li>
			    <li>Large-scale pre-training of foundation models on Earth imagery or simulation big data</li>
			    <li>Model and data parallelism for novel foundation models for spatiotemporal data</li>
			    <li>Energy efficiency and carbon footprint</li>
			    <li>Efficiency deployment on edge devices</li>
			    <li>Mobile computing systems using deep learning</li>
			    <li>GeoAI Cyberinfrastructure for Earth Science Applications</li>
			    <li>Geoinformation System (GIS) systems using deep learning</li>
			    <li>GeoAI scientific workflow development and optimization</li>
			    <li>Benchmarking AI on spatiotemporal problems, such as standardizing spatiotemporal datasets and metrics for GeoAI and Geo foundation model evaluation.</li>
			</ul>
			</p>

				</div>

			  </div>
			</div>
		  </div>
	
	
	<div class="site-section">
              <div class="block__73694 mb-2" id="paper-sub-section">
        			<div class="container">
        			  <div class="row d-flex no-gutters align-items-stretch">
        				<div class="col-lg-12" data-aos="" data-aos-delay="">
        				  <div align="center">
        				  <p class="mb-5 text-black"><font size="6"><b>Paper Submission</b></font></p>
        					  </div>

					<p class="mb-3 text-black">Important Dates: (all due Midnight Anywhere on Earth).<br/>
					    Paper submission deadline: <b>May 28, 2024</b><br/>
					    Paper review begins: <b>May 28, 2024</b>.<br/>
					    Paper review due: <b>June 27, 2024</b>.<br/>
					    Notification of decision: <b>June 28, 2024</b><br/>
					    Notifications to Workshop Chairs (number of papers, acceptance rate, etc.): <b>July 2nd, 2024</b><br/>
					    Camera-ready due: <b>July 10, 2024</b><br/>
					    Workshop Program Schedule and Full Website Online: <b>July 11, 2024</b><br/>
					    Workshop Date: <b>August 25, 2024</b></p>

        				  <p class="mb-3 text-black">The workshop welcomes the two types of submissions</p>
        				  <ul>
        				  <li><p class="mb-3 text-black">Full research papers – up to 9 pages (8 pages at most for the main body and the last page can only hold references)</p></li>
        				  <li><p class="mb-3 text-black">Vision papers and short system papers - up to 5 pages (4 pages at most for the main body and the last page can only hold references)</p></li>
        					</ul>
        			  	  <p class="mb-3 text-black">All manuscripts should be submitted in a single PDF file including all content, figures, tables, and references, following the format of KDD conference papers. Paper submissions need to include author information (review not double blinded). <br/><br/>Papers should be submitted at:<a href="https://easychair.org/conferences/?conf=deepspatial22"><span class="s4"> https://easychair.org/conferences/?conf=deepspatial22</span></a><br>Concurrent submissions to other journals and conferences are acceptable. Accepted papers will be presented as posters or short talks during the workshop and published on the workshop website. Besides, a small number of accepted papers may be selected to be presented as contributed talks. <u>As a tradition, accepted workshop papers are NOT included in the ACM Digital Library. The authors maintain the copyright of their papers</u>. </p>

        				</div>

        			  </div>
        			</div>
        		  </div>



	<div class="site-section">
		  <div class="block__73694 mb-2" id="contact-info">
			<div class="container">
			  <div class="row d-flex no-gutters align-items-stretch">
				<div class="col-lg-12" data-aos="" data-aos-delay="">
				  <div align="center">
				  <p class="mb-5 text-black"><font size="6"><b>Contact Information</b></font></p>
			      <p class="mb-3 text-black">
			              Zhe Jiang,  zhe.jiang@ufl.edu, Tel: (352) 294-6659<br/>
			              Liang Zhao, liang.zhao@emory.edu , Tel: (703) 993 5910<br/>
			              Xun Zhou,  xun-zhou@uiowa.edu, Tel: (319) 384-3335<br/>
			              Junbo Zhang, msjunbozhang@outlook.com<br/>
			              Robert Stewart,  stewartrn@ornl.gov, Tel: (865) 574-7646
				  </div>
				</div>
			  </div>
			</div>
		  </div>

		<div class="row pt-5 mt-5 text-center">
			<div class="col-md-12">
				<div class="border-top pt-5">
					<p class="copyright"><small>
		    <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
		    Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart text-danger" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank" >Colorlib</a>
		    <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
		    </small></p>
		    </div>
		  </div>

        </div>
      </div>
    </footer>

  </div>

  <script src="js/jquery-3.3.1.min.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.sticky.js"></script>
  <script src="js/jquery.waypoints.min.js"></script>
  <script src="js/jquery.animateNumber.min.js"></script>
  <script src="js/jquery.fancybox.min.js"></script>
  <script src="js/jquery.easing.1.3.js"></script>
  <script src="js/aos.js"></script>

  <script src="js/main.js"></script>

  </body>
</html>
